name: Model Training CI/CD Pipeline

on:
  push:
    branches:
      - main
      - develop
    paths:
      - 'src/training/**'
      - 'configs/**'
      - '.github/workflows/model_training_ci.yml'
  pull_request:
    branches:
      - main
      - develop
    paths:
      - 'src/training/**'
      - 'configs/**'
  workflow_dispatch:  # Allow manual triggering

jobs:
  model-training:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Set up environment variables
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      run: |
        echo "GOOGLE_API_KEY=$GOOGLE_API_KEY" >> $GITHUB_ENV
    
    - name: Check data availability
      run: |
        if [ ! -f "data-pipeline/data/processed/processed_discharge_summaries.csv" ]; then
          echo "Warning: Processed data not found. Pipeline may need data preparation step."
          exit 0
        fi
    
    - name: Run model training with validation
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      run: |
        python src/training/train_with_tracking.py \
          --data-path data-pipeline/data/processed/processed_discharge_summaries.csv \
          --config configs/gemini_config.json \
          --output-dir models/gemini \
          --run-name "ci-run-${{ github.run_number }}" \
          --disable-sensitivity || echo "Training completed with warnings"
      continue-on-error: true
    
    - name: Run model validation
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      run: |
        python -c "
        import sys
        sys.path.insert(0, 'src')
        from training import ModelValidator
        import pandas as pd
        
        # Load data
        df = pd.read_csv('data-pipeline/data/processed/processed_discharge_summaries.csv')
        
        # Sample for validation
        df_sample = df.head(10)
        
        # Initialize validator
        validator = ModelValidator()
        
        # For demonstration, use cleaned_text as both prediction and reference
        # In practice, you'd have actual predictions
        predictions = df_sample['cleaned_text'].astype(str).tolist()
        references = df_sample['cleaned_text'].astype(str).tolist()
        
        # Validate
        metrics = validator.validate_model(predictions, references)
        print(f'Validation metrics: {metrics}')
        
        # Check if metrics meet threshold
        if metrics.get('rougeL_f', 0) < 0.3:
            print('Warning: ROUGE-L F1 below threshold')
            sys.exit(1)
        "
      continue-on-error: true
    
    - name: Run bias detection
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      run: |
        python -c "
        import sys
        sys.path.insert(0, 'src')
        from training import ModelBiasDetector
        import pandas as pd
        
        # Load data
        df = pd.read_csv('data-pipeline/data/processed/processed_discharge_summaries.csv')
        
        # Sample for bias detection
        df_sample = df.head(20)
        
        # For demonstration, create dummy predictions
        df_sample['gemini_summary'] = df_sample['cleaned_text'].str[:100]
        
        # Initialize bias detector
        detector = ModelBiasDetector()
        
        # Detect bias
        bias_report = detector.detect_bias(
            df_sample,
            prediction_column='gemini_summary',
            reference_column='cleaned_text'
        )
        
        print(f'Bias score: {bias_report.get(\"overall_bias_score\", 0.0)}')
        print(f'Bias alerts: {len(bias_report.get(\"bias_alerts\", []))}')
        
        # Check if bias exceeds threshold
        if bias_report.get('overall_bias_score', 0.0) > 0.2:
            print('Warning: High bias detected')
            sys.exit(1)
        "
      continue-on-error: true
    
    - name: Upload MLflow artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: mlflow-runs
        path: mlruns/
        retention-days: 7
    
    - name: Upload model artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: model-artifacts
        path: models/
        retention-days: 7
    
    - name: Upload logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: training-logs
        path: logs/
        retention-days: 7
    
    - name: Check for rollback
      if: always()
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      run: |
        python -c "
        import sys
        sys.path.insert(0, 'src')
        from training import ModelRollback
        import mlflow
        
        # Get latest run ID
        mlflow.set_tracking_uri('./mlruns')
        experiment = mlflow.get_experiment_by_name('gemini-medical-summarization')
        if experiment:
            runs = mlflow.search_runs(
                experiment_ids=[experiment.experiment_id],
                order_by=['start_time DESC'],
                max_results=1
            )
            if not runs.empty:
                latest_run_id = runs.iloc[0]['run_id']
                rollback = ModelRollback()
                result = rollback.check_and_rollback(latest_run_id)
                if result.get('rollback_needed'):
                    print('WARNING: Rollback recommended!')
                    sys.exit(1)
        "
      continue-on-error: true
    
    - name: Notify on failure
      if: failure()
      run: |
        echo "Model training pipeline failed. Check logs for details."
        # In production, add Slack/email notification here
        # Example: curl -X POST -H 'Content-type: application/json' \
        #   --data '{\"text\":\"Model training failed\"}' \
        #   $SLACK_WEBHOOK_URL



