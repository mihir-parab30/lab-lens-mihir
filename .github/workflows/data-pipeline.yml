name: Data Pipeline

on:
  workflow_dispatch:
  schedule:
    - cron: '0 2 * * 0'  # Weekly Sunday 2 AM

jobs:
  run-pipeline:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - uses: actions/setup-python@v4
      with:
        python-version: '3.12'
    
    - name: Install dependencies
      run: |
        pip install pandas numpy google-cloud-bigquery scikit-learn
    
    - uses: google-github-actions/auth@v1
      with:
        credentials_json: ${{ secrets.GCP_SA_KEY }}
    
    - name: Run Data Pipeline
      run: |
        if [ -f "data-pipeline/scripts/main_pipeline.py" ]; then
          python data-pipeline/scripts/main_pipeline.py
          echo "✅ Pipeline completed"
        else
          echo "⚠️  Pipeline script not found"
        fi
    
    - uses: actions/upload-artifact@v3
      with:
        name: processed-data
        path: data-pipeline/data/processed/
